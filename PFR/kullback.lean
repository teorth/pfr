import PFR.Mathlib.Analysis.SpecialFunctions.NegMulLog
import PFR.ForMathlib.FiniteRange
import Mathlib.Probability.IdentDistrib

/-!
# Kullback-Leibler divergence

Definition of Kullback-Leibler divergence and basic facts

## Main definitions:


## Main results

-/

open MeasureTheory ProbabilityTheory Real

variable {Î© Î©' Î©'' Î©''' G: Type*}
  [mÎ© : MeasurableSpace Î©] {Î¼ : Measure Î©}
  [mÎ©' : MeasurableSpace Î©'] {Î¼' : Measure Î©'}
  [mÎ©'' : MeasurableSpace Î©''] {Î¼'' : Measure Î©''}
  [mÎ©''' : MeasurableSpace Î©'''] {Î¼''' : Measure Î©'''}
  [hG : MeasurableSpace G] [MeasurableSingletonClass G]

variable {X : Î© â†’ G} {Y : Î©' â†’ G} [FiniteRange X] [FiniteRange Y]

/--  If `X, Y` are two `G`-valued random variables, the Kullback--Leibler divergence is defined as
  `KL(X â€– Y) := âˆ‘â‚“ ð(X = x) log(ð(X = x) / ð(Y = x))`. -/
noncomputable def KL_div (X : Î© â†’ G) (Y: Î©' â†’ G) (Î¼: Measure Î©) (Î¼' : Measure Î©') : â„ := âˆ‘' x, (Î¼.map X {x}).toReal * log ((Î¼.map X {x}).toReal / (Î¼'.map Y {x}).toReal)

@[inherit_doc KL_div] notation3:max "KL[" X " ; " Î¼ " # " Y " ; " Î¼' "]" => KL_div X Y Î¼ Î¼'

/-- If `X'` is a copy of `X`, and `Y'` is a copy of `Y`, then `KL(X' â€– Y') = KL(X â€– Y)`. -/
lemma KL_div_eq_of_equiv (X' : Î©'' â†’ G) (Y' : Î©''' â†’ G) (hX : IdentDistrib X X' Î¼ Î¼'') (hY : IdentDistrib Y Y' Î¼' Î¼''') :
  KL[X ; Î¼ # Y ; Î¼'] = KL[X' ; Î¼'' # Y' ; Î¼'''] := sorry

/-- `KL(X â€– Y) â‰¥ 0`.-/
lemma KL_div_nonneg : KL[X ; Î¼ # Y ; Î¼'] â‰¥ 0 := sorry

/-- `KL(X â€– Y) = 0` if and only if `Y` is a copy of `X`. -/
lemma KL_div_eq_zero_iff_identDistrib : KL[X ; Î¼ # Y ; Î¼'] = 0 â†” IdentDistrib X Y Î¼ Î¼' := sorry
